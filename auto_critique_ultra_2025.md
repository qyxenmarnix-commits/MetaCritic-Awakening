# Алгоритмы улучшения тестов, инструкций и структуры промта (версия Ultra Critic)

---

## I. Контекст задачи
- Построение структуры и алгоритмов развития, анализа и оптимизации материалов (тесты НМТ, методички, auto-review)
- Внедрение Expert System с мульти-ролями: аналитик, критик, аудитор, оптимизатор, архитектор, git-структуратор
- Интеграция MIT/Stanford/Google best-practices + собственных алгоритмов критики, оценки, метрик, автотестов

## II. Пошаговый план (Auto-Expert Critique)
1. Извлечь и структурировать текущий контекст (summary, problem statement, ключевые траектории)
2. Провести системный аудит ошибок со стороны системы (инструкции, невыполненные условия, баги, автотесты)
3. Провести аудит пользовательских инструкций (неясность, избыточность, противоречия, слабые места)
4. Сформулировать инсайты, метарекомендации, выявить слабые и мощные аспекты системы
5. Алгоритмизировать защиту/расширение: чек-листы, auto-review, gap-finder, peer review
6. Выдать предложения по улучшению материалов и процесса создания тестов (структура, шаблоны, метрики качества)
7. Оформить для репозитория: выбрать папку, формат имя файла, релевантные ссылки/структуру

---

## III. Multi-Expert Roles (минимизация ошибок и увеличение глубины)
- На каждом шаге фиксируется критическая точка: всё ли учтено (role: Ultra Critic)? Проверка малых, скрытых, неявных деталей.
- Все материалы проходят минимум трёхуровневую проверку: self-check, auto-review, peer-review
- Каждый шаг сопровождается мета-чеклистом (см. ниже)

---

## IV. Структура чек-листа (для каждого этапа/материала)
- ✓ Контекст извлечён и понятен
- ✓ Ошибки системы найдены и разобраны
- ✓ Проверены формулировки инструкций пользователя
- ✓ Интегрированы инсайты и алгоритмы защиты/улучшения
- ✓ Есть предложения по оптимизации (пути, инструменты, тесты)
- ✓ Все действия — прозрачно задокументированы и опубликованы (git-log, ver control)
- ✓ Final meta-check: всё ли держится? Что осталось уязвимым?

---

## V. Метрики качества и предложения по автоматизации
- Вводить depth/completeness/impact score для каждого результата и итерации
- Auto-gap scan — авто-выявление неучтённых мест и слабых связей, недо-интеграции знаний
- Интеграция шаблонов OpenAI, Stanford, MIT в ревью и генерируемые auto-prompts
- Рекомендовать auto-integration со службой peer-review (второй ассистент)

---

## VI. Предложения для развития/тестирования:
- Добавлять модуль auto-critique на каждом этапе материала
- Строить тренировочные сеты "кейс-фейлов" и навертывать их на входе
- Вести публичный log изменений + версиирование всего
- Выпускать регулярные мастер-инструкции и апдейты (релизы, insights)
- Использовать динамическую карту weak points для всей интеллектуальной платформы

---

## VII. Инструкция для Deep Agent/ассистента
- По каждой новой задаче запускать мультирегулярный план: аналитик-критик-аудитор
- Встроенно держать чек-лист
- Публиковать анализ в виде md-файла
- Любое отклонение — фиксировать и генерировать micro-test на будущее
- Самостоятельно добавлять предложения, инсайты, вопросы и слабые зоны

---

## VIII. Итоговый self-check (финальная проверка)
- Покрыт ли весь спектр?
- Нет ли явных/скрытых слабых мест?
- Все ли этапы прошли? Проведен ли ревью?
- Все ли инсайты и предложения пригодны для практического внедрения?
- Есть ли roadmap для следующих шагов развития?

---

Автор: Агент Ultra Critic v2025, совместно с qyxenmarnix-commits
Дата последнего изменения: 2025-11-14

